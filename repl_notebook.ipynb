{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def read_meta(path, has_mmse):\n",
    "    df = pd.read_csv(\n",
    "        path, sep=';', names=['ID','age','gender'] + (['mmse'] if has_mmse else []),\n",
    "        skiprows=1, engine='python'\n",
    "    )\n",
    "    df.ID = df.ID.str.strip()\n",
    "    return df\n",
    "\n",
    "cc = read_meta(Path('train/transcription/cc_meta_data.txt'), True).assign(label=0)\n",
    "cd = read_meta(Path('train/transcription/cd_meta_data.txt'), True).assign(label=1)\n",
    "train_meta = pd.concat([cc, cd], ignore_index=True)\n",
    "\n",
    "test_meta = read_meta(Path('test/meta_data.txt'), False)\n",
    "\n",
    "train_paths = list(Path('train/transcription').rglob('*.cha'))\n",
    "test_paths  = list(Path('test/transcription').rglob('*.cha'))\n",
    "\n",
    "train_df = (\n",
    "    pd.DataFrame({'path': [str(p) for p in train_paths]})\n",
    "      .assign(ID=lambda d: d.path.map(lambda p: Path(p).stem))\n",
    "      .merge(train_meta[['ID','label']], on='ID')\n",
    "      .assign(split='train')\n",
    ")\n",
    "test_df = (\n",
    "    pd.DataFrame({'path': [str(p) for p in test_paths]})\n",
    "      .assign(ID=lambda d: d.path.map(lambda p: Path(p).stem))\n",
    "      .merge(test_meta[['ID']], on='ID')\n",
    "      .assign(label=-1, split='test')\n",
    ")\n",
    "\n",
    "df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "df.to_csv('transcript_paths.csv', index=False)\n",
    "print(\"Samples by split & label:\\n\", df.groupby(['split','label']).size())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nG7FxPmWUBlS",
    "outputId": "5c5b663f-2804-4efa-8d1a-768d3a74c85e"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Samples by split & label:\n",
      " split  label\n",
      "test   -1       47\n",
      "train   0       54\n",
      "        1       54\n",
      "dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "class TranscriptDataset(Dataset):\n",
    "    def __init__(self, paths, labels, tokenizer_name='bert-base-uncased', max_length=512):\n",
    "        self.paths      = paths\n",
    "        self.labels     = labels\n",
    "        self.tokenizer  = BertTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = Path(self.paths[idx]).read_text(encoding='utf-8').replace('\\n',' ')\n",
    "        enc  = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids':      enc.input_ids.squeeze(0),\n",
    "            'attention_mask': enc.attention_mask.squeeze(0),\n",
    "            'labels':         torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def make_dataloaders(df, batch_size=4, max_length=256):\n",
    "    train = df[df.split=='train']\n",
    "    test  = df[df.split=='test']\n",
    "\n",
    "    train_ds = TranscriptDataset(\n",
    "        train.path.tolist(), train.label.tolist(),\n",
    "        max_length=max_length\n",
    "    )\n",
    "    test_ds  = TranscriptDataset(\n",
    "        test.path.tolist(), test.label.tolist(),\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "id": "5ZvOH90aUDvD"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "\n",
    "class ADClassifier(torch.nn.Module):\n",
    "    def __init__(self, pretrained_model='bert-base-uncased', n_classes=2):\n",
    "        super().__init__()\n",
    "        self.bert       = BertModel.from_pretrained(pretrained_model)\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out    = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = out.pooler_output\n",
    "        return self.classifier(pooled)"
   ],
   "metadata": {
    "id": "fax3HmgvUFh6"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "\n",
    "class ADClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_classes=2):\n",
    "        super().__init__()\n",
    "        self.bert       = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        out    = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled = out.pooler_output\n",
    "        return self.classifier(pooled)\n"
   ],
   "metadata": {
    "id": "acohqcNdUG1V"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "from nltk.corpus import wordnet\n",
    "import numpy as np\n",
    "\n",
    "en2de = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")\n",
    "de2en = pipeline(\"translation_de_to_en\", model=\"Helsinki-NLP/opus-mt-de-en\")\n",
    "\n",
    "def back_translate(text):\n",
    "    de = en2de(text, max_length=512)[0]['translation_text']\n",
    "    return de2en(de, max_length=512)[0]['translation_text']\n",
    "\n",
    "def synonym_replace(text, pct=0.1):\n",
    "    words = text.split()\n",
    "    n     = max(1, int(len(words)*pct))\n",
    "    for idx in np.random.choice(len(words), n, replace=False):\n",
    "        syns = wordnet.synsets(words[idx])\n",
    "        if syns:\n",
    "            words[idx] = syns[0].lemmas()[0].name().replace('_',' ')\n",
    "    return ' '.join(words)\n",
    "\n",
    "def remove_pause(text):\n",
    "    return ' '.join(w for w in text.split() if w.lower() not in {'uh','um'})\n",
    "\n",
    "def apply_perturbation(text, method='none', pct=0.1):\n",
    "    if method=='bt':    return back_translate(text)\n",
    "    if method=='syn':   return synonym_replace(text, pct)\n",
    "    if method=='pause': return remove_pause(text)\n",
    "    return text"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ecw6IJjkUJun",
    "outputId": "7e2e6a98-2901-4204-b8d6-d1d0c99125f4"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def train_epoch(model, loader, opt, sched, device, epoch):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    print(f\"Epoch {epoch} training...\")\n",
    "    for step, batch in enumerate(loader, 1):\n",
    "        ids   = batch['input_ids'].to(device)\n",
    "        mask  = batch['attention_mask'].to(device)\n",
    "        lbls  = batch['labels'].to(device)\n",
    "\n",
    "        logits = model(ids, mask)\n",
    "        loss   = torch.nn.functional.cross_entropy(logits, lbls)\n",
    "        loss.backward()\n",
    "\n",
    "        opt.step(); sched.step(); opt.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if step % 20 == 0:\n",
    "            print(f\"    [Step {step}/{len(loader)}] avg loss {(total_loss/step):.4f}\")\n",
    "    avg = total_loss / len(loader)\n",
    "    print(f\"Epoch {epoch} training complete. Avg loss {avg:.4f}\\n\")\n",
    "    return avg\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, epoch):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    print(f\"Evaluating after Epoch {epoch}...\")\n",
    "    for batch in loader:\n",
    "        # Pull labels and mask out any test (label==-1)\n",
    "        labels = batch['labels'].cpu().tolist()\n",
    "        valid_mask = [l>=0 for l in labels]\n",
    "        if not any(valid_mask):\n",
    "            continue\n",
    "\n",
    "        # Select only valid examples\n",
    "        ids         = batch['input_ids'][valid_mask].to(device)\n",
    "        mask_tensor = batch['attention_mask'][valid_mask].to(device)\n",
    "        lbls_tensor = batch['labels'][valid_mask].to(device)\n",
    "\n",
    "        logits = model(ids, mask_tensor)\n",
    "        batch_preds = logits.argmax(-1).cpu().tolist()\n",
    "\n",
    "        preds.extend(batch_preds)\n",
    "        trues.extend(lbls_tensor.cpu().tolist())\n",
    "\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    f1  = f1_score(trues, preds)\n",
    "    print(f\"Eval Epoch {epoch}: Acc={acc:.4f}, F1={f1:.4f}\\n\")\n",
    "    return acc, f1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"🖥  Using device:\", device)\n",
    "\n",
    "df = pd.read_csv('transcript_paths.csv')\n",
    "train_loader, test_loader = make_dataloaders(df, batch_size=4, max_length=256)\n",
    "print(f\"Train samples: {len(train_loader.dataset)}, Eval samples (with labels): {sum(1 for _,l in zip(test_loader.dataset.paths, test_loader.dataset.labels) if l>=0)}\\n\")\n",
    "\n",
    "model = ADClassifier().to(device)\n",
    "epochs = 10\n",
    "total_steps = len(train_loader) * epochs\n",
    "opt   = AdamW(model.parameters(), lr=2e-5)\n",
    "sched = get_linear_schedule_with_warmup(opt, num_warmup_steps=int(0.1*total_steps), num_training_steps=total_steps)\n",
    "\n",
    "best_f1 = 0.0\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = train_epoch(model, train_loader, opt, sched, device, epoch)\n",
    "    acc, f1    = evaluate(model, test_loader, device, epoch)\n",
    "\n",
    "    if f1 > best_f1:\n",
    "        best_f1 = f1\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "        print(f\"New best F1={f1:.4f} saved to best_model.pt\\n\")\n",
    "\n",
    "print(\"Training complete.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_9nJtTiLUKQe",
    "outputId": "8b634659-f7d7-4ea7-8594-3aa15804ad37"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🖥  Using device: cpu\n",
      "📊  Train samples: 108, Eval samples (with labels): 0\n",
      "\n",
      "🔄  Epoch 1 training...\n",
      "    [Step 20/27] avg loss 0.6999\n",
      "✅  Epoch 1 training complete. Avg loss 0.7012\n",
      "\n",
      "🔍  Evaluating after Epoch 1...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 1: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 2 training...\n",
      "    [Step 20/27] avg loss 0.6944\n",
      "✅  Epoch 2 training complete. Avg loss 0.6939\n",
      "\n",
      "🔍  Evaluating after Epoch 2...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 2: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 3 training...\n",
      "    [Step 20/27] avg loss 0.4717\n",
      "✅  Epoch 3 training complete. Avg loss 0.3925\n",
      "\n",
      "🔍  Evaluating after Epoch 3...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 3: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 4 training...\n",
      "    [Step 20/27] avg loss 0.0778\n",
      "✅  Epoch 4 training complete. Avg loss 0.0659\n",
      "\n",
      "🔍  Evaluating after Epoch 4...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 4: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 5 training...\n",
      "    [Step 20/27] avg loss 0.0197\n",
      "✅  Epoch 5 training complete. Avg loss 0.0181\n",
      "\n",
      "🔍  Evaluating after Epoch 5...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 5: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 6 training...\n",
      "    [Step 20/27] avg loss 0.0109\n",
      "✅  Epoch 6 training complete. Avg loss 0.0103\n",
      "\n",
      "🔍  Evaluating after Epoch 6...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 6: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 7 training...\n",
      "    [Step 20/27] avg loss 0.0078\n",
      "✅  Epoch 7 training complete. Avg loss 0.0075\n",
      "\n",
      "🔍  Evaluating after Epoch 7...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/numpy/lib/_function_base_impl.py:552: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis, **keepdims_kw)\n",
      "/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py:145: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "🎯  Eval Epoch 7: Acc=nan, F1=0.0000\n",
      "\n",
      "🔄  Epoch 8 training...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch, pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ADClassifier().to(device)\n",
    "model.load_state_dict(torch.load('best_model.pt', map_location=device))\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "df = pd.read_csv('transcript_paths.csv')\n",
    "test = df[df.split=='test'].reset_index(drop=True)\n",
    "\n",
    "records = []\n",
    "for method in ['none','bt','syn','pause']:\n",
    "    for pct in [0.1, 0.3, 0.5]:\n",
    "        correct = 0\n",
    "        for _, row in test.iterrows():\n",
    "            text = Path(row.path).read_text(encoding='utf-8')\n",
    "            pert = apply_perturbation(text, method, pct)\n",
    "            enc  = tokenizer(pert, truncation=True, padding='max_length',\n",
    "                             max_length=256, return_tensors='pt').to(device)\n",
    "            logits = model(enc.input_ids, enc.attention_mask)\n",
    "            pred   = logits.argmax(-1).item()\n",
    "            # If you have true label in row.label, compare; otherwise skip\n",
    "            if row.label >= 0 and pred == row.label:\n",
    "                correct += 1\n",
    "        acc = correct / len(test) if row.label>=0 else None\n",
    "        records.append({'method': method, 'pct': pct, 'accuracy': acc})\n",
    "\n",
    "print(pd.DataFrame(records).pivot('pct','method','accuracy'))"
   ],
   "metadata": {
    "id": "1l7N139eUMD5"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
